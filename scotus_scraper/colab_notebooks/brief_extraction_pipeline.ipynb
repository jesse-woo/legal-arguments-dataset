{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ZIu6SjUCBzr"
      },
      "source": [
        "A pipeline to read briefs from pdf, preprocess them, extract the arguments from the table of contents, and split the brief into sections"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IsJNwT7ZB63c",
        "outputId": "2fdef62c-beb7-48a7-bc54-ad8e2f645760"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3wj0Nt-aE9dC",
        "outputId": "41a6a1e6-b25c-470b-c5b2-b3cd414633a2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pycryptodome in /usr/local/lib/python3.10/dist-packages (3.20.0)\n",
            "Requirement already satisfied: pypdf2 in /usr/local/lib/python3.10/dist-packages (3.0.1)\n",
            "Requirement already satisfied: fuzzywuzzy in /usr/local/lib/python3.10/dist-packages (0.18.0)\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (1.26.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.27.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.7.1)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.4)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai) (4.11.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.7)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.2.2)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.5)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.2 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.18.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install pycryptodome pypdf2 fuzzywuzzy openai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z0M2eJyHFpqB"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import PyPDF2\n",
        "import pandas as pd\n",
        "from Crypto.Cipher import AES\n",
        "from PyPDF2.errors import PdfReadError\n",
        "\n",
        "def extract_with_pypdf2(pdf_path):\n",
        "  try:\n",
        "    with open(pdf_path, 'rb') as file:\n",
        "        pdf_reader = PyPDF2.PdfReader(file)\n",
        "\n",
        "        full_text = \"\"\n",
        "\n",
        "        if pdf_reader.is_encrypted:\n",
        "            # Attempt to decrypt it with an empty password\n",
        "            try:\n",
        "                pdf_reader.decrypt('')\n",
        "            except Exception as e:\n",
        "                return f\"Failed to decrypt PDF: {e}\"\n",
        "\n",
        "        # Iterate through each page in the PDF\n",
        "        for page in pdf_reader.pages:\n",
        "            page_text = page.extract_text()\n",
        "\n",
        "            # Append the page text to the full text of the document\n",
        "            if page_text: \n",
        "                full_text += page_text + \"\\n\"\n",
        "\n",
        "    return full_text\n",
        "  except (PdfReadError, TypeError )as e:\n",
        "    print(f\"PDF read error in {pdf_path}: {e}\")\n",
        "    return None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "-cEH1wX9F_hQ",
        "outputId": "faa54165-c0bf-4400-a2da-457da5e7ad85"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\ndata = []  # List to store file path and text data\\ndirectory = \"/content/drive/MyDrive/LLM/brief_pdfs\"\\nfiles = os.listdir(directory)\\nfor filename in files:\\n  if filename.endswith(\".pdf\"):\\n    file_path = os.path.join(directory, filename)\\n    text = extract_with_pypdf2(file_path)\\n    if text is not None:  # Check if text extraction was successful\\n      data.append({\\'filename\\': filename, \\'text\\': text})\\npdf_df = pd.DataFrame(data)\\n'"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "'''\n",
        "data = []  # List to store file path and text data\n",
        "directory = \"/content/drive/MyDrive/LLM/brief_pdfs\"\n",
        "files = os.listdir(directory)\n",
        "for filename in files:\n",
        "  if filename.endswith(\".pdf\"):\n",
        "    file_path = os.path.join(directory, filename)\n",
        "    text = extract_with_pypdf2(file_path)\n",
        "    if text is not None:  # Check if text extraction was successful\n",
        "      data.append({'filename': filename, 'text': text})\n",
        "pdf_df = pd.DataFrame(data)\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wUrRZh-7XYwu"
      },
      "outputs": [],
      "source": [
        "# pdf_df = pd.DataFrame(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uGMrnGXdSuM_"
      },
      "outputs": [],
      "source": [
        "# print(len(data))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A9bciQCiJWKk"
      },
      "outputs": [],
      "source": [
        "# print(pdf_df.head)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "27jMtOnSd7ve"
      },
      "outputs": [],
      "source": [
        "# pdf_df.to_csv('/content/drive/MyDrive/LLM/extracted_briefs_ckpt.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iWShPILa3Rcl"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "toc_df = pd.read_csv('/content/drive/MyDrive/LLM/extracted_briefs_ckpt.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U-LUYAKOKGgR"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "\n",
        "def extract_toc_and_rest(content):\n",
        "    toc_pattern = r\"TABLE OF CONTENTS\"\n",
        "    toa_pattern = r\"TABLE OF AUTHORITIES(?![ .]{2,})\"\n",
        "    # toa_pattern = r\"TABLE OF AUTHORITIES\"\n",
        "    conclusion_pattern = r\"(CONCLUSION|Conclusion)\"\n",
        "\n",
        "    def extract_text(start_pattern, end_pattern, content):\n",
        "        start_indices = [m.start() for m in re.finditer(start_pattern, content)]\n",
        "        end_indices = [m.start() for m in re.finditer(end_pattern, content)]\n",
        "\n",
        "         # Check if there is at least one start index and one end index\n",
        "        if not start_indices or not end_indices:\n",
        "            return None, None\n",
        "\n",
        "        # Use the first start index\n",
        "        start_index = start_indices[0]\n",
        "\n",
        "        # Use the last end index, ensuring it is after the start index\n",
        "        end_index = next((i for i in reversed(end_indices) if i > start_index), None)\n",
        "\n",
        "        if end_index is not None:\n",
        "            return content[start_index:end_index], end_index\n",
        "        else:\n",
        "            return content[start_index:], len(content)\n",
        "\n",
        "    toc, toc_end_index = extract_text(toc_pattern, toa_pattern, content)\n",
        "\n",
        "    if toc is None or len(toc.strip()) <= len('TABLE OF CONTENTS PagePage'):\n",
        "        toc, toc_end_index = extract_text(toc_pattern, conclusion_pattern, content)\n",
        "\n",
        "    rest_of_content = content[toc_end_index:] if toc_end_index is not None else None\n",
        "\n",
        "    return toc, rest_of_content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kP7VsH6K8c5M",
        "outputId": "7aefcf4f-1ac7-46de-fa4b-f507004d7549"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dropped 169 rows of empty or very short text\n"
          ]
        }
      ],
      "source": [
        "# Remove briefs that where text is null bc of pdf reading issues or they are very short\n",
        "# usually because they are not actually briefs or were read improperly\n",
        "old_len = len(toc_df)\n",
        "toc_df = toc_df[(toc_df['text'].notnull()) & (toc_df['text'].str.len() >= 15000)]\n",
        "toc_df = toc_df.reset_index(drop=True)\n",
        "\n",
        "print(f\"Dropped {old_len - len(toc_df)} rows of empty or very short text\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ua5i8jfp5502"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "\n",
        "# Function to split brief text into the TOC and Content by finding and slicing off everything after Conclusion\n",
        "def split_text(text):\n",
        "  conclusion_match = re.search(r'CONCLUSIONS?\\b', text, flags=re.MULTILINE | re.IGNORECASE)\n",
        "  if conclusion_match:\n",
        "      # If a match is found, slice after conclusion\n",
        "      # print(\"Here is the match for conclusion\")\n",
        "      # print(conclusion_match)\n",
        "      toc_text = text[:conclusion_match.start()]\n",
        "      content_text = text[conclusion_match.end():]\n",
        "      return toc_text, content_text\n",
        "  else:\n",
        "    # toa_match = re.search(r'^Table of Authorities\\b', text, flags=re.MULTILINE | re.IGNORECASE)\n",
        "\n",
        "    toa_match = re.search(r'^Table\\s+of\\s+Authorities\\b', text, flags=re.MULTILINE | re.IGNORECASE)\n",
        "    if not toa_match:\n",
        "      # If still no match, look for any line containing \"Authorities\"\n",
        "      toa_match = re.search(r'^.*?\\bAuthorities\\b.*$', text, flags=re.MULTILINE | re.IGNORECASE)\n",
        "\n",
        "\n",
        "    if toa_match:\n",
        "      # If a match for \"Table of Authorities\" is found, split the text at that point\n",
        "      toc_text = text[:toa_match.start()]\n",
        "      content_text = text[toa_match.end():]\n",
        "      return toc_text, content_text\n",
        "    return None, None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zowBAMgW4ADd",
        "outputId": "38a3206c-8c5f-46c7-edb6-95d5b8c0488e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "toc_df updated with 'toc' and 'content' columns.\n"
          ]
        }
      ],
      "source": [
        "# Apply the extract_toc_and_rest function to the 'text' field and store the results in new columns\n",
        "toc_df[['toc', 'content']] = toc_df.apply(lambda row: pd.Series(split_text(row['text'])), axis=1)\n",
        "\n",
        "# Now, toc_df contains all the original fields, plus the 'toc' and 'content' columns with the extracted data\n",
        "print(\"toc_df updated with 'toc' and 'content' columns.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nF68770NKPGp",
        "outputId": "0e92b134-9025-4f26-9696-dcbf0a878bdb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "toc_df updated with docket number column.\n"
          ]
        }
      ],
      "source": [
        "def extract_docket_number(filename):\n",
        "    match = re.search(r'Docket(\\d+-\\d+)_', filename)\n",
        "    if match:\n",
        "        return match.group(1)\n",
        "    else:\n",
        "        return None\n",
        "\n",
        "toc_df[['docket_num']] = toc_df.apply(lambda row: pd.Series(extract_docket_number(row['filename'])), axis=1)\n",
        "\n",
        "# Now, toc_df contains all the original fields, plus the 'toc' and 'content' columns with the extracted data\n",
        "print(\"toc_df updated with docket number column.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cBolmZTWO4Jv"
      },
      "outputs": [],
      "source": [
        "toc_df['court'] = 'SCOTUS'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pr378rBfNRwL",
        "outputId": "78e5aeb0-f413-4798-b7e1-5578dba5639d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dropped 11 rows of empty toc/content\n"
          ]
        }
      ],
      "source": [
        "# Remove briefs that where toc or content is null\n",
        "# usually because of an issue with text parsing\n",
        "old_len = len(toc_df)\n",
        "# & (toc_df['content'].str.len() >= 4000)\n",
        "toc_df = toc_df[((toc_df['toc'].notnull()) | (toc_df['content'].notnull())) ]\n",
        "toc_df = toc_df.reset_index(drop=True)\n",
        "\n",
        "print(f\"Dropped {old_len - len(toc_df)} rows of empty toc/content\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O7nZaCGtWDeW",
        "outputId": "1caa90de-bbf5-4eb3-bf58-fcc9c83d222b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dropped 213 rows of empty or very short content\n"
          ]
        }
      ],
      "source": [
        "# Remove briefs that where toc or content is null\n",
        "# usually because of an issue with text parsing\n",
        "# Based on manual testing below for content, 4000 is a tight bound and 10000 is a loose one for finding short content.\n",
        "old_len = len(toc_df)\n",
        "toc_df = toc_df[(toc_df['content'].str.len() >= 5000)]\n",
        "toc_df = toc_df.reset_index(drop=True)\n",
        "\n",
        "print(f\"Dropped {old_len - len(toc_df)} rows of empty or very short content\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4C85TMq9OUZd",
        "outputId": "836dd6b0-e3df-4a1e-fbbd-71709a8439a6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<bound method NDFrame.head of                         filename  \\\n",
            "0     Docket20-5279_Brief007.pdf   \n",
            "1     Docket20-5279_Brief008.pdf   \n",
            "2     Docket20-5279_Brief009.pdf   \n",
            "3     Docket20-5279_Brief010.pdf   \n",
            "4      Docket20-828_Brief001.pdf   \n",
            "...                          ...   \n",
            "3974  Docket16-1027_Brief009.pdf   \n",
            "3975  Docket16-1027_Brief010.pdf   \n",
            "3976   Docket17-387_Brief001.pdf   \n",
            "3977   Docket17-387_Brief002.pdf   \n",
            "3978   Docket17-387_Brief003.pdf   \n",
            "\n",
            "                                                   text  \\\n",
            "0     No. 20-5279  \\n \\nIN THE \\nSupreme Court of th...   \n",
            "1     No. 20-5279 \\nIN THE \\nSupreme Court of the Un...   \n",
            "2      \\n No. 20-5279  \\nIn the Supreme Court of the...   \n",
            "3      \\n \\n \\n \\n \\n \\nNo. 20-5279 \\n \\n In the Sup...   \n",
            "4      \\n No. 20-828 \\n=============================...   \n",
            "...                                                 ...   \n",
            "3974  No. 16-1027\\nIn the Supreme Court of the Unite...   \n",
            "3975   \\n No. 16-1027 \\n============================...   \n",
            "3976   \\n \\nNo. 17 -387 \\n \\n \\nIN THE \\nSUPREME COU...   \n",
            "3977   \\n No. 17-387 \\nIn the Supreme Court of the U...   \n",
            "3978   \\n \\n No. 17-387 \\nIn the Supreme Court of th...   \n",
            "\n",
            "                                                    toc  \\\n",
            "0     No. 20-5279  \\n \\nIN THE \\nSupreme Court of th...   \n",
            "1     No. 20-5279 \\nIN THE \\nSupreme Court of the Un...   \n",
            "2      \\n No. 20-5279  \\nIn the Supreme Court of the...   \n",
            "3      \\n \\n \\n \\n \\n \\nNo. 20-5279 \\n \\n In the Sup...   \n",
            "4      \\n No. 20-828 \\n=============================...   \n",
            "...                                                 ...   \n",
            "3974  No. 16-1027\\nIn the Supreme Court of the Unite...   \n",
            "3975   \\n No. 16-1027 \\n============================...   \n",
            "3976   \\n \\nNo. 17 -387 \\n \\n \\nIN THE \\nSUPREME COU...   \n",
            "3977   \\n No. 17-387 \\nIn the Supreme Court of the U...   \n",
            "3978   \\n \\n No. 17-387 \\nIn the Supreme Court of th...   \n",
            "\n",
            "                                                content docket_num   court  \n",
            "0      ................................................    20-5279  SCOTUS  \n",
            "1      28 \\niii \\nTABLE OF AUTHORITIES \\nPage(s) \\nC...    20-5279  SCOTUS  \n",
            "2       ................................ ..............    20-5279  SCOTUS  \n",
            "3     , but only  as a matter of statutory pur-\\npos...    20-5279  SCOTUS  \n",
            "4       ...............................................     20-828  SCOTUS  \n",
            "...                                                 ...        ...     ...  \n",
            "3974   ................................................    16-1027  SCOTUS  \n",
            "3975   ................................................    16-1027  SCOTUS  \n",
            "3976    ...............................................     17-387  SCOTUS  \n",
            "3977    ................................ ..............     17-387  SCOTUS  \n",
            "3978    ...............................................     17-387  SCOTUS  \n",
            "\n",
            "[3979 rows x 6 columns]>\n"
          ]
        }
      ],
      "source": [
        "print(toc_df.head)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kbr_7sOwZ7Tj"
      },
      "outputs": [],
      "source": [
        "# toc_df.to_csv('/content/drive/MyDrive/LLM/extracted_briefs_ckpt_2.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nIsmlSw_gxM3"
      },
      "outputs": [],
      "source": [
        "toc_df = pd.read_csv('/content/drive/MyDrive/LLM/extracted_briefs_ckpt_2.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wQAJGiF88ePM",
        "outputId": "12576bda-4467-4249-d2fb-77a6eb2537ae"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of cases: 360\n"
          ]
        }
      ],
      "source": [
        "# Count number of unique cases\n",
        "unique_ids = list(toc_df['docket_num'].unique())\n",
        "print(f\"Number of cases: {len(unique_ids)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J2xUrUvm-GfO",
        "outputId": "19725877-2003-469a-fa50-cb0485a57551"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average number of tokens per entry: 8956.003769791405\n"
          ]
        }
      ],
      "source": [
        "# Tokenize each entry and count tokens\n",
        "toc_df['token_count'] = toc_df['text'].apply(lambda x: len(x.split()) if pd.notnull(x) else 0)\n",
        "\n",
        "# Calculate the average number of tokens\n",
        "average_tokens = toc_df['token_count'].mean()\n",
        "\n",
        "print(\"Average number of tokens per entry:\", average_tokens)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UrcZLXxvaqeK"
      },
      "source": [
        "Preprocess the toc to extract only the argument headers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-w6ak9-BaNhg"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "def clean_table_of_contents(toc_text):\n",
        "    # Stage 1: Find the arguments\n",
        "    # Remove standalone page numbers without a period. Must do this before removing periods below.\n",
        "    toc_text = re.sub(r'^\\s*\\d+\\s*$', '', toc_text, flags=re.MULTILINE)\n",
        "    # Attempt to find the start of the arguments to extract. This will likely fail on some number of cases\n",
        "    pattern = r'(Arguments?|Reasons?\\s+for).*\\n?'\n",
        "    matches = re.search(pattern, toc_text, re.MULTILINE | re.IGNORECASE)\n",
        "    # print(\"Here are the matches\")\n",
        "    # print(matches)\n",
        "    if not matches:\n",
        "        # print(\"oopsie no matches\")\n",
        "        return None\n",
        "    toc_text = toc_text[matches.end():]\n",
        "    # print(f\"After matching on Argument, the ToC looks like: \\n{toc_text}\")\n",
        "    # Stage 2: Use re.search to find \"CONCLUSION\" on a line by itself, case-insensitive\n",
        "\n",
        "    conclusion_match = re.search(r'CONCLUSIONS?\\b', toc_text, flags=re.MULTILINE | re.IGNORECASE) #remove ^ character?\n",
        "    if conclusion_match:\n",
        "        # If a match is found, slice after conclusion\n",
        "        # print(\"Here is the match for conclusion\")\n",
        "        # print(conclusion_match)\n",
        "        toc_text = toc_text[:conclusion_match.start()]\n",
        "        # print(f\"After matching on Conclusion, the ToC looks like: \\n{toc_text}\")\n",
        "\n",
        "    # Now split on the periods\n",
        "    split_text = re.split(r'\\.\\s*\\.\\s*\\.\\s*.*$', toc_text, flags=re.MULTILINE)\n",
        "    # Removing empty strings and None elements that might result from capturing groups in the split\n",
        "\n",
        "    # Finally, iterate through each line and apply other preprocessing steps, mainly removing periods and roman numerals\n",
        "    processed_text = []\n",
        "    for index, text in enumerate(split_text):\n",
        "      # text = re.sub(r'\\.{2,}', ' ', text)  # Replace periods\n",
        "      text = re.sub(r'\\.\\s*\\.\\s*\\.\\s*.*$', '', text, flags=re.MULTILINE) # Find any sequence of three periods, with any amount of space after them, and remove the rest of the line\n",
        "      # text = re.sub(r'(\\.\\s){2,}.*$', '', text, flags=re.MULTILINE)\n",
        "\n",
        "      # Remove lowercase Roman numerals at the end of lines, ensuring they're not part of section titles\n",
        "      text = re.sub(r'^\\s*(i{1,3}|iv|vi{0,3}|ix|xi{0,3}|xii{0,3}|xiii|xiv|xv)\\s*[\\.\\s]*$', '', text, flags=re.MULTILINE)\n",
        "      # Remove spaces before newlines\n",
        "      text = re.sub(r'[ \\t]+$', '', text, flags=re.MULTILINE)\n",
        "      text = re.sub(r'\\n+', ' ', text)\n",
        "      text = text.strip()\n",
        "\n",
        "      # Special condition for the first item in the list\n",
        "      if index == 0:\n",
        "        # Remove \"Argument\" followed by any punctuation or space at the start of the line\n",
        "        text = re.sub(r'^Argument[\\s.,;:!?-]*', '', text, flags=re.IGNORECASE)\n",
        "      # Look for section indicators to remove any extra tokens at start of the line\n",
        "      pattern = r'(I\\.|II\\.|III\\.|IV\\.|V\\.|VI\\.|VII\\.|VIII\\.|IX\\.|X\\.|1\\.|2\\.|3\\.|4\\.|5\\.|6\\.|7\\.|8\\.|9\\.|10\\.|A\\.|B\\.|C\\.|D\\.|E\\.|F\\.|G\\.|H\\.|I\\.|J\\.)'\n",
        "      match = re.search(pattern, text)\n",
        "\n",
        "      if match:\n",
        "        text = text[match.start():]\n",
        "\n",
        "      if text: # Ensure non-empty, non-whitespace only sections are kept\n",
        "        processed_text.append(text)\n",
        "\n",
        "    split_text = [s for s in split_text if s and s.strip()]\n",
        "    return processed_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i8Xc1gJAfon2"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "\n",
        "def remove_conclusion(content_text):\n",
        "  # Find all matches of \"CONCLUSION\" using re.finditer, which returns an iterator yielding match objects\n",
        "  matches = list(re.finditer(r'CONCLUSIONS?\\b', content_text, flags=re.MULTILINE | re.IGNORECASE))\n",
        "\n",
        "  if matches:\n",
        "    # If matches are found, take the last match\n",
        "    last_match = matches[-1]\n",
        "    # Remove conclusion and everything after the last occurrence of \"CONCLUSION\"\n",
        "    content_text = content_text[:last_match.start()]\n",
        "\n",
        "  return content_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-videaQ_goYi",
        "outputId": "625bc958-c0eb-4ff4-ee92-c22ec9d0157f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<bound method NDFrame.head of                         filename  \\\n",
            "0     Docket20-5279_Brief007.pdf   \n",
            "1     Docket20-5279_Brief008.pdf   \n",
            "2     Docket20-5279_Brief009.pdf   \n",
            "3     Docket20-5279_Brief010.pdf   \n",
            "4      Docket20-828_Brief001.pdf   \n",
            "...                          ...   \n",
            "3974  Docket16-1027_Brief009.pdf   \n",
            "3975  Docket16-1027_Brief010.pdf   \n",
            "3976   Docket17-387_Brief001.pdf   \n",
            "3977   Docket17-387_Brief002.pdf   \n",
            "3978   Docket17-387_Brief003.pdf   \n",
            "\n",
            "                                                   text  \\\n",
            "0     No. 20-5279  \\n \\nIN THE \\nSupreme Court of th...   \n",
            "1     No. 20-5279 \\nIN THE \\nSupreme Court of the Un...   \n",
            "2      \\n No. 20-5279  \\nIn the Supreme Court of the...   \n",
            "3      \\n \\n \\n \\n \\n \\nNo. 20-5279 \\n \\n In the Sup...   \n",
            "4      \\n No. 20-828 \\n=============================...   \n",
            "...                                                 ...   \n",
            "3974  No. 16-1027\\nIn the Supreme Court of the Unite...   \n",
            "3975   \\n No. 16-1027 \\n============================...   \n",
            "3976   \\n \\nNo. 17 -387 \\n \\n \\nIN THE \\nSUPREME COU...   \n",
            "3977   \\n No. 17-387 \\nIn the Supreme Court of the U...   \n",
            "3978   \\n \\n No. 17-387 \\nIn the Supreme Court of th...   \n",
            "\n",
            "                                                    toc  \\\n",
            "0     No. 20-5279  \\n \\nIN THE \\nSupreme Court of th...   \n",
            "1     No. 20-5279 \\nIN THE \\nSupreme Court of the Un...   \n",
            "2      \\n No. 20-5279  \\nIn the Supreme Court of the...   \n",
            "3      \\n \\n \\n \\n \\n \\nNo. 20-5279 \\n \\n In the Sup...   \n",
            "4      \\n No. 20-828 \\n=============================...   \n",
            "...                                                 ...   \n",
            "3974  No. 16-1027\\nIn the Supreme Court of the Unite...   \n",
            "3975   \\n No. 16-1027 \\n============================...   \n",
            "3976   \\n \\nNo. 17 -387 \\n \\n \\nIN THE \\nSUPREME COU...   \n",
            "3977   \\n No. 17-387 \\nIn the Supreme Court of the U...   \n",
            "3978   \\n \\n No. 17-387 \\nIn the Supreme Court of th...   \n",
            "\n",
            "                                                content docket_num   court  \n",
            "0      ................................................    20-5279  SCOTUS  \n",
            "1      28 \\niii \\nTABLE OF AUTHORITIES \\nPage(s) \\nC...    20-5279  SCOTUS  \n",
            "2       ................................ ..............    20-5279  SCOTUS  \n",
            "3     , but only  as a matter of statutory pur-\\npos...    20-5279  SCOTUS  \n",
            "4       ...............................................     20-828  SCOTUS  \n",
            "...                                                 ...        ...     ...  \n",
            "3974   ................................................    16-1027  SCOTUS  \n",
            "3975   ................................................    16-1027  SCOTUS  \n",
            "3976    ...............................................     17-387  SCOTUS  \n",
            "3977    ................................ ..............     17-387  SCOTUS  \n",
            "3978    ...............................................     17-387  SCOTUS  \n",
            "\n",
            "[3979 rows x 6 columns]>\n"
          ]
        }
      ],
      "source": [
        "print(toc_df.head)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2q5TCWGegcjW"
      },
      "outputs": [],
      "source": [
        "toc_df['arguments'] = toc_df['toc'].apply(clean_table_of_contents)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nuTifi0NgHqv"
      },
      "outputs": [],
      "source": [
        "toc_df['content'] = toc_df['content'].apply(lambda x: remove_conclusion(x) if pd.notnull(x) else x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S5HL4WuKqGBG"
      },
      "outputs": [],
      "source": [
        "def clean_content(content):\n",
        "  return re.sub(r'(?<![\\.\\?!])\\n(?!\\n)', ' ', content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BKsJ7Oqhqhea"
      },
      "outputs": [],
      "source": [
        "toc_df['content'] = toc_df['content'].apply(lambda x: clean_content(x) if pd.notnull(x) else x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DauR4zuUhpQp",
        "outputId": "fdab0aa8-1635-4eff-fb26-d497af4498f9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<bound method NDFrame.head of                         filename  \\\n",
            "0     Docket20-5279_Brief007.pdf   \n",
            "1     Docket20-5279_Brief008.pdf   \n",
            "2     Docket20-5279_Brief009.pdf   \n",
            "3     Docket20-5279_Brief010.pdf   \n",
            "4      Docket20-828_Brief001.pdf   \n",
            "...                          ...   \n",
            "3974  Docket16-1027_Brief009.pdf   \n",
            "3975  Docket16-1027_Brief010.pdf   \n",
            "3976   Docket17-387_Brief001.pdf   \n",
            "3977   Docket17-387_Brief002.pdf   \n",
            "3978   Docket17-387_Brief003.pdf   \n",
            "\n",
            "                                                   text  \\\n",
            "0     No. 20-5279  \\n \\nIN THE \\nSupreme Court of th...   \n",
            "1     No. 20-5279 \\nIN THE \\nSupreme Court of the Un...   \n",
            "2      \\n No. 20-5279  \\nIn the Supreme Court of the...   \n",
            "3      \\n \\n \\n \\n \\n \\nNo. 20-5279 \\n \\n In the Sup...   \n",
            "4      \\n No. 20-828 \\n=============================...   \n",
            "...                                                 ...   \n",
            "3974  No. 16-1027\\nIn the Supreme Court of the Unite...   \n",
            "3975   \\n No. 16-1027 \\n============================...   \n",
            "3976   \\n \\nNo. 17 -387 \\n \\n \\nIN THE \\nSUPREME COU...   \n",
            "3977   \\n No. 17-387 \\nIn the Supreme Court of the U...   \n",
            "3978   \\n \\n No. 17-387 \\nIn the Supreme Court of th...   \n",
            "\n",
            "                                                    toc  \\\n",
            "0     No. 20-5279  \\n \\nIN THE \\nSupreme Court of th...   \n",
            "1     No. 20-5279 \\nIN THE \\nSupreme Court of the Un...   \n",
            "2      \\n No. 20-5279  \\nIn the Supreme Court of the...   \n",
            "3      \\n \\n \\n \\n \\n \\nNo. 20-5279 \\n \\n In the Sup...   \n",
            "4      \\n No. 20-828 \\n=============================...   \n",
            "...                                                 ...   \n",
            "3974  No. 16-1027\\nIn the Supreme Court of the Unite...   \n",
            "3975   \\n No. 16-1027 \\n============================...   \n",
            "3976   \\n \\nNo. 17 -387 \\n \\n \\nIN THE \\nSUPREME COU...   \n",
            "3977   \\n No. 17-387 \\nIn the Supreme Court of the U...   \n",
            "3978   \\n \\n No. 17-387 \\nIn the Supreme Court of th...   \n",
            "\n",
            "                                                content docket_num   court  \\\n",
            "0      ................................................    20-5279  SCOTUS   \n",
            "1      28  iii  TABLE OF AUTHORITIES  Page(s)  Cases...    20-5279  SCOTUS   \n",
            "2       ................................ ..............    20-5279  SCOTUS   \n",
            "3     , but only  as a matter of statutory pur- pose...    20-5279  SCOTUS   \n",
            "4       ...............................................     20-828  SCOTUS   \n",
            "...                                                 ...        ...     ...   \n",
            "3974   ................................................    16-1027  SCOTUS   \n",
            "3975   ................................................    16-1027  SCOTUS   \n",
            "3976    ...............................................     17-387  SCOTUS   \n",
            "3977    ................................ ..............     17-387  SCOTUS   \n",
            "3978    ...............................................     17-387  SCOTUS   \n",
            "\n",
            "                                              arguments  \n",
            "0                                                  None  \n",
            "1     [I. AN EXPANSIVE INTERPRETATION OF THE ARMED C...  \n",
            "2     [Petitioner’s 1997 burglary convictions are fo...  \n",
            "3     [6.  The Government similarly relies (a t 14, ...  \n",
            "4     [A.   The Ninth Circuit’s Decision Must Be Re-...  \n",
            "...                                                 ...  \n",
            "3974  [The Officers Were Required To Obtain A Warran...  \n",
            "3975  [I.   The automobile ex ception to the warrant...  \n",
            "3976  [I. Federal Courts and Congress Have Long Reco...  \n",
            "3977  [I. State courts cannot circumvent tribal sove...  \n",
            "3978  [A. A State has in rem  jurisdiction over acti...  \n",
            "\n",
            "[3979 rows x 7 columns]>\n"
          ]
        }
      ],
      "source": [
        "print(toc_df.head)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "obC4tSbjlyHI",
        "outputId": "71bdcd7c-0fb7-4bfc-deb5-b1e6d19ed5d9"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/fuzzywuzzy/fuzz.py:11: UserWarning: Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning\n",
            "  warnings.warn('Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning')\n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "from fuzzywuzzy import process, fuzz\n",
        "\n",
        "# match headers to sections and delete the headers within sections to avoid data leaks\n",
        "def new_match_headers_to_sections(row, threshold=70):\n",
        "    headers = row['arguments']\n",
        "    content = row['content']\n",
        "\n",
        "    # Check if either headers or content is None or if headers is not a list\n",
        "    if headers is None or content is None or not isinstance(headers, list):\n",
        "        return None\n",
        "\n",
        "    lines = content.split('\\n')\n",
        "    matched_sections = {}\n",
        "    section_starts = []\n",
        "\n",
        "    # Find match points for headers\n",
        "    for header in headers:\n",
        "        high_score = 0\n",
        "        best_match = None\n",
        "        for line in lines:\n",
        "            score = fuzz.token_sort_ratio(header, line)\n",
        "            if score > high_score:\n",
        "                high_score = score\n",
        "                best_match = line\n",
        "            if score > threshold:\n",
        "                break  # Assuming line order in content follows headers logically\n",
        "        '''\n",
        "        print(f\"The header is: {header}\")\n",
        "        print(f\"Best match is: {best_match}\")\n",
        "        print(f\"The score is: {high_score}\")\n",
        "        '''\n",
        "        if best_match and high_score > threshold:\n",
        "            match_index = lines.index(best_match)\n",
        "            section_starts.append(match_index)\n",
        "            matched_sections[header] = best_match\n",
        "\n",
        "    # Create sections from matches\n",
        "    sections = []\n",
        "    for i in range(len(section_starts)):\n",
        "        start_idx = section_starts[i]\n",
        "        end_idx = section_starts[i + 1] if i + 1 < len(section_starts) else len(lines)\n",
        "        section_content = \"\\n\".join(lines[start_idx:end_idx])\n",
        "        # Match the last 4 words in the header to the section to find its end, and slice off the header.\n",
        "        # Use regex to find the position of the last four words of the header in the section_content\n",
        "        last_four_words = ' '.join(headers[i].split()[-4:])  # Get last four words of the header\n",
        "        # print(f\"The last 4 words are: {last_four_words}\")\n",
        "        regex_pattern = re.escape(last_four_words) + r'.*?(?=\\n|$)'  # Regex to find these words followed by anything until a newline or end of string\n",
        "        match = re.search(regex_pattern, section_content, re.DOTALL)  # DOTALL to make '.' match newlines as well\n",
        "        # print(f\"The match is {match}\")\n",
        "        if match:\n",
        "            # Update section_content to start after the matched header\n",
        "            section_content = section_content[match.end():].strip()  # Start after the end of the match\n",
        "        # Replace empty or whitespace-only strings with None\n",
        "        if not section_content.strip():\n",
        "            section_content = None\n",
        "        sections.append({headers[i]: section_content})\n",
        "\n",
        "    # sections_json = json.dumps(sections, indent=4) # Possibly return a JSON instead\n",
        "    return sections"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        },
        "id": "mZthhi4-mX0C",
        "outputId": "c2b7a484-9ec1-4096-c68b-e6502b6dd350"
      },
      "outputs": [
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-32-89664936a605>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtoc_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sections'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtoc_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_match_headers_to_sections\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthreshold\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m80\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, axis, raw, result_type, args, **kwargs)\u001b[0m\n\u001b[1;32m   9421\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   9422\u001b[0m         )\n\u001b[0;32m-> 9423\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__finalize__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"apply\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   9424\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   9425\u001b[0m     def applymap(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    676\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_raw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 678\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_standard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    679\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    680\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0magg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    796\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    797\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_standard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 798\u001b[0;31m         \u001b[0mresults\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mres_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_series_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    799\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    800\u001b[0m         \u001b[0;31m# wrap results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply_series_generator\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    812\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseries_gen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    813\u001b[0m                 \u001b[0;31m# ignore SettingWithCopy here in case the user mutates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 814\u001b[0;31m                 \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    815\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mABCSeries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    816\u001b[0m                     \u001b[0;31m# If we have a view on v, we need to make a copy because\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mf\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m             \u001b[0;32mdef\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 133\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-31-4fdea4e8691c>\u001b[0m in \u001b[0;36mnew_match_headers_to_sections\u001b[0;34m(row, threshold)\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mbest_match\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlines\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m             \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfuzz\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoken_sort_ratio\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mheader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mscore\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mhigh_score\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m                 \u001b[0mhigh_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/fuzzywuzzy/fuzz.py\u001b[0m in \u001b[0;36mtoken_sort_ratio\u001b[0;34m(s1, s2, force_ascii, full_process)\u001b[0m\n\u001b[1;32m    103\u001b[0m     \u001b[0mbut\u001b[0m \u001b[0msorting\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mtoken\u001b[0m \u001b[0mbefore\u001b[0m \u001b[0mcomparing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m     \"\"\"\n\u001b[0;32m--> 105\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_token_sort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpartial\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_ascii\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_ascii\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfull_process\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfull_process\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/fuzzywuzzy/utils.py\u001b[0m in \u001b[0;36mdecorator\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecorator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/fuzzywuzzy/fuzz.py\u001b[0m in \u001b[0;36m_token_sort\u001b[0;34m(s1, s2, partial, force_ascii, full_process)\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mpartial_ratio\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msorted1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msorted2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mratio\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msorted1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msorted2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/fuzzywuzzy/utils.py\u001b[0m in \u001b[0;36mdecorator\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecorator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/fuzzywuzzy/utils.py\u001b[0m in \u001b[0;36mdecorator\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecorator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/fuzzywuzzy/utils.py\u001b[0m in \u001b[0;36mdecorator\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecorator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/fuzzywuzzy/fuzz.py\u001b[0m in \u001b[0;36mratio\u001b[0;34m(s1, s2)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0mm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSequenceMatcher\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mratio\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/difflib.py\u001b[0m in \u001b[0;36mratio\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    617\u001b[0m         \"\"\"\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 619\u001b[0;31m         \u001b[0mmatches\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtriple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtriple\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_matching_blocks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    620\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_calculate_ratio\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmatches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/difflib.py\u001b[0m in \u001b[0;36mget_matching_blocks\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    452\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mqueue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m             \u001b[0malo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mahi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mblo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbhi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mqueue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 454\u001b[0;31m             \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_longest_match\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mahi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mblo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbhi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    455\u001b[0m             \u001b[0;31m# a[alo:i] vs b[blo:j] unknown\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m             \u001b[0;31m# a[i:i+k] same as b[j:j+k]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/difflib.py\u001b[0m in \u001b[0;36mfind_longest_match\u001b[0;34m(self, alo, ahi, blo, bhi)\u001b[0m\n\u001b[1;32m    377\u001b[0m             \u001b[0mj2lenget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mj2len\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m             \u001b[0mnewj2len\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 379\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mb2j\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnothing\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    380\u001b[0m                 \u001b[0;31m# a[i] matches b[j]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mj\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mblo\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "toc_df['sections'] = toc_df.apply(new_match_headers_to_sections, axis=1, threshold=80)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iixb_KjIexsJ"
      },
      "source": [
        "Confirm that extraction worked properly"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YS6A-SLd90A1"
      },
      "outputs": [],
      "source": [
        "mask = toc_df['sections'].apply(lambda x: x == [] or x is None)\n",
        "\n",
        "empty_sec_df = toc_df[mask].reset_index(drop=True)\n",
        "# Invert the mask to keep rows where the condition is False\n",
        "df_complete = toc_df[~mask]\n",
        "\n",
        "print(f\"There are {len(empty_sec_df)} rows with empty sections\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UgF-MKw6-jBP"
      },
      "outputs": [],
      "source": [
        "print(empty_sec_df.head)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oH0CRwHFQMUC"
      },
      "outputs": [],
      "source": [
        "print(df_complete.head)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GbyjhlED-qlC"
      },
      "outputs": [],
      "source": [
        "print(toc_df['sections'].head)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4BOjKRvQ-2Uy"
      },
      "outputs": [],
      "source": [
        "print(toc_df['sections'].iloc[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "meIDKXR_bVAB"
      },
      "outputs": [],
      "source": [
        "regex_toc_df = toc_df['toc'].apply(clean_table_of_contents) # Apply regex to the whole column, save as new df to test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FCEsrl2Nbuij"
      },
      "outputs": [],
      "source": [
        "idx = 3000\n",
        "print(toc_df.iloc[idx]['toc'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l2GFcbQ_cOyM"
      },
      "outputs": [],
      "source": [
        "for thing in regex_toc_df.iloc[idx]:\n",
        "  print(thing)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s5wUlGaBew8a"
      },
      "outputs": [],
      "source": [
        "idx = 3\n",
        "print(\"TOC:\")\n",
        "print(toc_df.iloc[idx][\"toc\"])\n",
        "print(\"CONTENTS:\")\n",
        "print(toc_df.iloc[idx][\"content\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RSZZJyzTDiyr"
      },
      "outputs": [],
      "source": [
        "print(toc_df.iloc[idx][\"text\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lTRPjtbHPQnH"
      },
      "outputs": [],
      "source": [
        "idx = 3812\n",
        "print(\"TOC:\")\n",
        "print(toc_df.iloc[idx][\"toc\"])\n",
        "print(\"CONTENTS:\")\n",
        "print(toc_df.iloc[idx][\"content\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ymy54Kp7PT1S"
      },
      "outputs": [],
      "source": [
        "print(toc_df.iloc[idx][\"text\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KQoKSzsfMhv7"
      },
      "outputs": [],
      "source": [
        "# Unclear if this is necessary to clean up null rows\n",
        "# Create a boolean mask where True indicates rows to be removed\n",
        "mask = toc_df['toc'].isnull() | (toc_df['toc'].str.len() < 100)\n",
        "\n",
        "# Invert the mask to keep rows where the condition is False\n",
        "df_cleaned = toc_df[~mask]\n",
        "\n",
        "mask = toc_df['toc'].isnull() | (toc_df['toc'].str.len() < 100)\n",
        "empty_toc_df = toc_df[mask].reset_index(drop=True)\n",
        "\n",
        "print(f\"There are {len(empty_toc_df)} rows with empty toc\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bb-q7LLOET6p"
      },
      "outputs": [],
      "source": [
        "print(empty_toc_df.head)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fd1m3I2y7J9q"
      },
      "outputs": [],
      "source": [
        "mask = (toc_df['text'].str.len() < 15000)\n",
        "\n",
        "# Invert the mask to keep rows where the condition is False\n",
        "df_cleaned = toc_df[~mask]\n",
        "\n",
        "empty_text_df = toc_df[mask].reset_index(drop=True)\n",
        "\n",
        "print(f\"There are {len(empty_text_df)} rows with empty text\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T3SrXWgP7hHV"
      },
      "outputs": [],
      "source": [
        "print(empty_toc_df.head)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hrsqzOdE7qxX"
      },
      "outputs": [],
      "source": [
        "# print(empty_toc_df.iloc[3]['text'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xfWAd1bHPKvY"
      },
      "outputs": [],
      "source": [
        "mask = (toc_df['content'].str.len() < 10000)\n",
        "\n",
        "# Invert the mask to keep rows where the condition is False\n",
        "df_cleaned = toc_df[~mask]\n",
        "\n",
        "short_content_df = toc_df[mask].reset_index(drop=True)\n",
        "\n",
        "print(f\"There are {len(short_content_df)} rows with short content\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RXwDHiHYQVOK"
      },
      "outputs": [],
      "source": [
        "print(short_content_df.head)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M65Dxcs6Qb4t"
      },
      "outputs": [],
      "source": [
        "idx = 0\n",
        "print(short_content_df.iloc[idx]['toc'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ez_Ai5LGS_k6"
      },
      "outputs": [],
      "source": [
        "print(short_content_df.iloc[idx]['content'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nRhVz5JsXX0J"
      },
      "outputs": [],
      "source": [
        "text = \"\"\"\n",
        "There isn’t one thing that stands out that I can say:\n",
        "That’s it.  That’s what I miss the most.”  Id. at 48-17.\n",
        "Sean’s stepfather, Joseph Rogers, said that Sean\n",
        "“was a cop at an early age.”  Id. at 48-20.  During col-\n",
        "lege, Sean “was a volunteer for the Somerville Auxil-iary Police” and “was the youngest sergeant they had\n",
        "ever had.”  Id. at 48-22.  Once Sean graduated from\n",
        "college, the Somerville Police Department “sponsored him to the MBTA Transit Police Academy,” and “[i]n\n",
        "2010, he graduated from the MBTA Police Academy\n",
        "with “the highest grade point average of anybody who had ever graduated.”  Id. at 48-22 to -23.  The day he\n",
        "\n",
        "surviving spectators’ testimony had relevance to the jury’s\n",
        "weighing of aggravating factors other than victim impact.”  Pet. App. 98a.\n",
        "17\n",
        "graduated from the Academy was “[p]robably the hap-\n",
        "piest day of his life.”  Id. at 48-27 to -28.\n",
        "Mr. Rogers recounted how he learned that Sean\n",
        "had been murdered:  “they took us to see Sean. * * *\n",
        "He had a hole in the middle of his head and he was\n",
        "shot to pieces.  And he’s la ying there.  They don’t re-\n",
        "ally clean you up much; they just wipe off the blood.\n",
        "And my wife is touching him and his blood is coming\n",
        "up in her hands.”  Id. at 48-29.  Since Sean’s death,\n",
        "his mother has “been diagnosed with having post-\n",
        "traumatic stress disorder.  She keeps remembering\n",
        "that night and being told, wh at he looked like, and it\n",
        "runs over in her mind.”  Id. at 48-29 to -30.  Each of\n",
        "Sean’s six siblings was severely impacted:  one sibling\n",
        "“moved to Texas and that way it’s easier for her not to talk about it.”  Id. at 48-32.  Another sibling “has had\n",
        "to deal with a lot of the press, the unending press that\n",
        "we get, and that’s been ve ry difficult on her and her\n",
        "marriage.”  Id.\n",
        "The jury also heard vict im-impact testimony from\n",
        "the family members of the three people murdered by\n",
        "the bombing, plus testimony from many injured sur-\n",
        "vivors.  The survivors testified about how the shrapnel\n",
        "bombs that respondent detonated mutilated their bod-ies, and how the bombings unleashed a flood of psy-\n",
        "chological and emotional torm ent.  One survivor testi-\n",
        "fied that he was “in a very dark place” and “not want-ing to live” anymore.  Pet. App. 100a.  Another was\n",
        "unable to testify because he checked himself in to a\n",
        "mental-health facility as a result of the bombings.  Id.\n",
        "Because the court of appeals vacated respondent’s\n",
        "death sentence, the distri ct court must “empanel a\n",
        "new jury, and preside over a new trial strictly limited\n",
        "to what penalty [respondent] should get on the death-\n",
        "eligible counts.”  Pet. App. 3a (citation omitted).  That\n",
        "\"\"\"\n",
        "\n",
        "# Count characters\n",
        "num_characters = len(text)\n",
        "\n",
        "print(\"Number of characters in the text:\", num_characters)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uWyC-hrtN_Zm"
      },
      "source": [
        "Try using OpenAI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "63lhr_2gOPmh"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from openai import OpenAI\n",
        "\n",
        "text = toc_df.iloc[0][\"text\"]\n",
        "key = \"sk-proj-HPuEBXpZczveh29SCWUvT3BlbkFJfqW3TJTN0n3xVmF3egEp\"\n",
        "client = OpenAI(api_key=key)\n",
        "response = client.chat.completions.create(\n",
        "  model=\"gpt-3.5-turbo\",\n",
        "  messages=[\n",
        "    {\"role\": \"system\", \"content\": \"You are a helpful legal assistant who specializes in reading legal documents and extracting exact text.\"},\n",
        "    {\"role\": \"user\", \"content\": f\"Read this text and extract the extract the arguments in the form of section headings that appear in the table of contents. Extract the arguments exactly as they appear in the table, preserving indentation, linebreak, and things like roman numerals and lettering of sections. {text}\"},\n",
        "  ]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8h6BrnwHRBcU"
      },
      "outputs": [],
      "source": [
        "print(response.choices[0].message.content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kl4HCCsNXnYu"
      },
      "outputs": [],
      "source": [
        "print(text)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
